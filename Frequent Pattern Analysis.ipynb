{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 1 - Frequent Pattern Analysis\n",
    "Name: <\n",
    "insert name here>\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but you must write all code and solutions on your own.\n",
    "\n",
    "The rules to be followed for the assignment are:\n",
    "\n",
    "Do NOT load additional packages beyond what we've shared in the cells below.\n",
    "Some problems with code may be autograded. If we provide a function or class API do not change it.\n",
    "Do not change the location of the data or data directory. Use only relative paths to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle5 as pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Problem 1 - Apriori Implementation\n",
    "A sample dataset has been provided to you in the './data/dataset.pickle' path. Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "Dataset should load the transactions in the form of a python dictionary where each key holds the transaction id and the value is a python list of the items purchased in that transaction.\n",
    "An example transaction will have the following structure. If items A, C, D, F are purchased in transaction T3, this would appear as follows in the dictionary.\n",
    "transactions = {\n",
    "   \"T3\": [\"A\", \"C\", \"D\", \"F\"]\n",
    "}\n",
    "Note:\n",
    "\n",
    "A sample dataset to test your code has been provided in the location \"./data/dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "Do not change the variable names of the returned values.\n",
    "After calculating each of those values, assign them to the corresponding value that is being returned.\n",
    "\n",
    "If you are encountering any errors while loading the dataset, the following lines of code should help. Please delete the cells before submitting, to reduce any potential autograder issues.\n",
    "\n",
    "Terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pickle5\n",
    "\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "  \n",
    "def findsubsets(s, n):\n",
    "    \n",
    "#   A helper function that you can use to list of all subsets of size n. Do not make any changes to this code block.\n",
    "#   Input: \n",
    "#       1. s - A python list of items\n",
    "#       2. n - Size of each subset\n",
    "#   Output:\n",
    "#       1. subsets - A python list containing the subsets of size n.\n",
    "    \n",
    "    subsets = list(sorted((itertools.combinations(s,n))))\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_from_frequent_itemsets(frequent_itemset):\n",
    "\n",
    "#   A helper function that you can use to get the sorted items from the frequent itemsets. Do not make any changes\n",
    "#   to this code block\n",
    "#   Input:\n",
    "#       1. Frequent Itemsets\n",
    "#   Output:\n",
    "#       1. Sorted list of items\n",
    "\n",
    "    items = list()\n",
    "    for keys in frequent_itemset.keys():\n",
    "        for item in list(keys):\n",
    "            items.append(item)\n",
    "    return sorted(list(set(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frequent_itemsets(dataset, support, items, n=1, frequent_items={}):\n",
    "    \n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions.\n",
    "#       2. support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#       3. items - A python list representing all the items that are part of all the transactions.\n",
    "#       4. n - An integer variable representing what frequent item pairs to generate.\n",
    "#       5. frequent_items - A dictionary representing k-1 frequent sets. \n",
    "#   Output:\n",
    "#       1. frequent_itemsets - A dictionary representing the frequent itemsets and their corresponding support counts.\n",
    "    \n",
    "    len_transactions = len(dataset)\n",
    "    \n",
    "    frequent_itemsets = {}\n",
    "    if n == 1:\n",
    "        for item in items:\n",
    "            support_count = 0\n",
    "            for transaction in dataset.values():\n",
    "                if item in transaction:\n",
    "                    support_count += 1\n",
    "            if support_count / len_transactions >= support:\n",
    "                frequent_items[item] = support_count\n",
    "        \n",
    "        # Get the frequent itemsets of size 1\n",
    "        frequent_itemsets = frequent_items\n",
    "    \n",
    "    else:\n",
    "          # Get the frequent itemsets of size n-1\n",
    "        frequent_k_1_itemsets = frequent_items\n",
    "        \n",
    "        # Get all possible subsets of size n from the frequent itemsets of size n-1\n",
    "        for subset in findsubsets(list(frequent_k_1_itemsets.keys()), n):\n",
    "            \n",
    "            # Get the support count for the current subset\n",
    "            support_count = 0\n",
    "            for transaction in dataset.values():\n",
    "                if all(item in transaction for item in subset):\n",
    "                    support_count += 1\n",
    "            if support_count / len_transactions >= support:\n",
    "                frequent_itemsets[tuple(subset)] = support_count\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        # your code here\n",
    "    return frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grade cell: cell-9189aa11b7c2f094Score: 10.0 / 10.0 (Top)\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n",
    "\n",
    "Hidden Tests Redacted\n",
    "Congratulations! All test cases in this cell passed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestX(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.min_support = 0.5\n",
    "        self.items = ['A', 'B', 'C', 'D', 'E']\n",
    "        self.dataset = dict()\n",
    "        self.dataset[\"T1\"] = ['A', 'B', 'D']\n",
    "        self.dataset[\"T2\"] = ['A', 'B', 'E']\n",
    "        self.dataset[\"T3\"] = ['B', 'C', 'D']\n",
    "        self.dataset[\"T4\"] = ['B', 'D', 'E']        \n",
    "        self.dataset[\"T5\"] = ['A', 'B', 'C', 'D']\n",
    "        \n",
    "    def test0(self):\n",
    "        frequent_1_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items)\n",
    "        print (frequent_1_itemsets)\n",
    "        frequent_1_itemsets_solution = dict()\n",
    "        frequent_1_itemsets_solution['A'] = 3\n",
    "        frequent_1_itemsets_solution['B'] = 5\n",
    "        frequent_1_itemsets_solution['D'] = 4\n",
    "\n",
    "        print (\"Test 1: frequent 1 itemsets\")\n",
    "        assert frequent_1_itemsets == frequent_1_itemsets_solution\n",
    "\n",
    "        frequent_2_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items, 2, frequent_1_itemsets)\n",
    "        print (frequent_2_itemsets)\n",
    "        frequent_2_itemsets_solution = dict()\n",
    "        frequent_2_itemsets_solution[('A', 'B')] = 3\n",
    "        frequent_2_itemsets_solution[('B', 'D')] = 4\n",
    "        \n",
    "        print (\"Test 1: frequent 2 itemsets\")\n",
    "        assert frequent_2_itemsets == frequent_2_itemsets_solution\n",
    "\n",
    "        frequent_3_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items, 3, frequent_2_itemsets)\n",
    "        print (frequent_3_itemsets)\n",
    "        frequent_3_itemsets_solution = dict()\n",
    "        \n",
    "\n",
    "        print (\"Test 1: frequent 3 itemsets\")\n",
    "        assert frequent_3_itemsets == frequent_3_itemsets_solution         \n",
    "   \n",
    "tests=TestX()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Problem 2 - FP-Growth Implementation\n",
    "A sample dataset has been provided to you in the './data/dataset.pickle' path. Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "Dataset should load the transactions in the form of a python dictionary where each key holds the transaction id and the value is a python list of the items purchased in that transaction.\n",
    "An example transaction will have the following structure. If items A, C, D, F are purchased in transaction T3, this would appear as follows in the dictionary.\n",
    "transactions = {\n",
    "   \"T3\": [\"A\", \"C\", \"D\", \"F\"]\n",
    "}\n",
    "Note:\n",
    "\n",
    "A sample dataset to test your code has been provided in the location \"./data/dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "Do not change the variable names of the returned values.\n",
    "After calculating each of those values, assign them to the corresponding value that is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_support(dataset, min_support):\n",
    "    \n",
    "#   A helper function that returns the support count of each item in the dataset.\n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions. \n",
    "#       2. min_support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#   Output:\n",
    "#       1. support_dict - A dictionary representing the support count of each item in the dataset.\n",
    "    \n",
    "    len_transactions = len(dataset)\n",
    "    support_dict = dict()\n",
    "    for key, value in dataset.items():\n",
    "        for item in value:\n",
    "            if item not in support_dict:\n",
    "                support_dict[item] = 0\n",
    "            support_dict[item] += 1\n",
    "        \n",
    "        # your code here\n",
    "        \n",
    "    \n",
    "    ### For reference only\n",
    "    sorted_support = dict(sorted(support_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    pruned_support = {key:val for key, val in sorted_support.items() if val/len_transactions >= min_support}\n",
    "    ###\n",
    "    \n",
    "    return support_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has visible test cases that you can run to see if you are on the right track!\n",
    "# Note: hidden tests will also be applied on other datasets for final grading.\n",
    "\n",
    "dataset = dict()\n",
    "with open('./data/dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "\n",
    "support_dict = item_support(dataset, 0.5)\n",
    "support_dict_expected = {'C': 7, 'D': 9, 'E': 5, 'B': 6, 'A': 6}\n",
    "\n",
    "print(f'The expected support_dict value for the given dataset is: {support_dict_expected}')\n",
    "print(f'Your support_dict value is: {support_dict}')\n",
    "\n",
    "try:\n",
    "    assert support_dict == support_dict_expected\n",
    "    print(\"Visible tests passed!\")\n",
    "except:\n",
    "    print(\"Visible tests failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grade cell: cell-330eca95a174c213Score: 2.0 / 2.0 (Top)\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n",
    "\n",
    "Hidden Tests Redacted\n",
    "Congratulations! All test cases in this cell passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_transactions(dataset, min_support):\n",
    "    \n",
    "#   A helper function that reorders the transaction items based on maximum support count. It is important that you finish\n",
    "#   the code in the previous cells since this function makes use of the support count dictionary calculated above.\n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions. \n",
    "#       2. min_support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#   Output:\n",
    "#       1. updated_dataset - A dictionary representing the transaction items in sorted order of their support counts.\n",
    "\n",
    "    pruned_support = item_support(dataset, min_support) \n",
    "    updated_dataset = dict()\n",
    "    \n",
    "    # This loop sorts the transaction items based on the item support counts\n",
    "    for key, value in dataset.items():\n",
    "        updated_dataset[key] = sorted(value, key=pruned_support.get, reverse=True)\n",
    "   \n",
    "    # Update the following loop to remove items that do not belong to the pruned_support dictionary\n",
    "    for key, value in updated_dataset.items():\n",
    "        updated_values = list()\n",
    "        for item in value:\n",
    "            if item in value:\n",
    "                if item in pruned_support:\n",
    "                    updated_values.append(item)\n",
    "            # your code here\n",
    "            \n",
    "        updated_dataset[key] = updated_values\n",
    "    \n",
    "    return updated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has visible test cases that you can run to see if you are on the right track!\n",
    "# Note: hidden tests will also be applied on other datasets for final grading.\n",
    "\n",
    "import pprint\n",
    "import json\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "\n",
    "dataset = dict()\n",
    "with open('./data/dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "\n",
    "updated_dataset = reorder_transactions(dataset, 0.5)\n",
    "updated_dataset_expected = {'T1': ['D', 'C', 'E'], 'T2': ['D', 'C', 'B'], 'T3': ['D', 'C', 'A'],\n",
    "                            'T4': ['D', 'C', 'A', 'E'], 'T5': ['D', 'C', 'A', 'B'], 'T6': ['B'],\n",
    "                            'T7': ['D', 'E'], 'T8': ['D', 'C', 'A', 'B'], 'T9': ['D', 'A', 'B', 'E'], 'T10': ['D', 'C', 'A', 'B', 'E']}\n",
    "\n",
    "print(f'The expected updated_dataset value for the given dataset is:')\n",
    "pp.pprint(updated_dataset_expected)\n",
    "print(f'Your updated_dataset value is:')\n",
    "pp.pprint(updated_dataset)\n",
    "\n",
    "try:\n",
    "    assert updated_dataset == updated_dataset_expected\n",
    "    print(\"Visible tests passed!\")\n",
    "except:\n",
    "    print(\"Visible tests failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grade cell: cell-f75886c98dbd692bScore: 2.0 / 2.0 (Top)\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n",
    "\n",
    "Hidden Tests Redacted\n",
    "Congratulations! All test cases in this cell passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp_tree(updated_dataset):\n",
    "    \n",
    "#   Input: \n",
    "#       1. updated_dataset - A python dictionary containing the updated set of transactions based on the pruned support dictionary.\n",
    "#   Output:\n",
    "#       1. fp_tree - A dictionary representing the fp_tree. Each node should have a count and children attribute.\n",
    "#        \n",
    "#   HINT:\n",
    "#       1. Loop over each transaction in the dataset and make an update to the fp_tree dictionary. \n",
    "#       2. For each loop iteration store a pointer to the previously visited node and update it's children in the next pass.\n",
    "#       3. Update the root pointer when you start processing items in each transaction.\n",
    "#       4. Reset the root pointer for each transaction.\n",
    "#\n",
    "#   Sample Tree Output:\n",
    "#   {'Y': {'count': 3, 'children': {'V': {'count': 1, 'children': {}}}},\n",
    "#    'X': {'count': 2, 'children': {'R': {'count': 1, 'children': {'F': {'count': 1, 'children': {}}}}}}}\n",
    "\n",
    "    \n",
    "    fp_tree = dict()\n",
    "    \n",
    "    \n",
    "    fp_tree[\"children\"]={}\n",
    "    for key, value in updated_dataset.items():\n",
    "        node =fp_tree\n",
    "        for item in value:\n",
    "            if item not in node[\"children\"]:\n",
    "                node[\"children\"][item]={\"count\": 0, \"children\": {}}\n",
    "            node=node[\"children\"][item]\n",
    "            node[\"count\"]+=1\n",
    "        \n",
    "        \n",
    "        # your code here\n",
    "        \n",
    "    return fp_tree[\"children\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has visible test cases that you can run to see if you are on the right track!\n",
    "# Note: hidden tests will also be applied on other datasets for final grading.\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=8)\n",
    "\n",
    "dataset = dict()\n",
    "with open('./data/dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "\n",
    "updated_dataset = reorder_transactions(dataset, 0.5)\n",
    "\n",
    "fp_tree = build_fp_tree(updated_dataset)\n",
    "fp_tree_expected = {'D': {'count': 9,\n",
    "  'children': {'C': {'count': 7,\n",
    "    'children': {'E': {'count': 1, 'children': {}},\n",
    "     'B': {'count': 1, 'children': {}},\n",
    "     'A': {'count': 5,\n",
    "      'children': {'E': {'count': 1, 'children': {}},\n",
    "       'B': {'count': 3, 'children': {'E': {'count': 1, 'children': {}}}}}}}},\n",
    "   'E': {'count': 1, 'children': {}},\n",
    "   'A': {'count': 1,\n",
    "    'children': {'B': {'count': 1,\n",
    "      'children': {'E': {'count': 1, 'children': {}}}}}}}},\n",
    " 'B': {'count': 1, 'children': {}}}\n",
    "\n",
    "print(f'The expected fp_tree value for the given dataset is:')\n",
    "pp.pprint(fp_tree_expected)\n",
    "print(f'\\nYour fp_tree value is:')\n",
    "pp.pprint(fp_tree)\n",
    "\n",
    "try:\n",
    "    assert fp_tree == fp_tree_expected\n",
    "    print(\"Visible tests passed!\")\n",
    "except:\n",
    "    print(\"Visible tests failed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grade cell: cell-2e8a2c6ab7c275e5Score: 6.0 / 6.0 (Top)\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n",
    "\n",
    "Hidden Tests Redacted\n",
    "Congratulations! All test cases in this cell passed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
